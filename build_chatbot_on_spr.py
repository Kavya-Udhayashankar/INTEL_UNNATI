# -*- coding: utf-8 -*-
"""build_chatbot_on_spr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16a5wp-HxbuJA_d_ZiR8cZp64aumNut2P

NeuralChat is a customizable chat framework designed to create user own chatbot within few minutes on multiple architectures. This notebook is used to demonstrate how to build a talking chatbot on 4th Generation of IntelÂ® XeonÂ® Scalable Processors Sapphire Rapids.

The 4th Generation of IntelÂ® XeonÂ® Scalable processor provides two instruction sets viz. AMX_BF16 and AMX_INT8 which provides acceleration for bfloat16 and int8 operations respectively.

# Prepare Environment

Install intel extension for transformers:
"""

!pip install intel-extension-for-transformers

"""Install Requirements:"""

!git clone https://github.com/intel/intel-extension-for-transformers.git

# Commented out IPython magic to ensure Python compatibility.
# %cd ./intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/
!pip install -r requirements_cpu.txt
# %cd ../../../

"""# Build your chatbot ðŸ’»

## Text Chat

Giving NeuralChat the textual instruction, it will respond with the textual response.
"""

# BF16 Optimization
from intel_extension_for_transformers.neural_chat import build_chatbot, PipelineConfig
from intel_extension_for_transformers.transformers import MixedPrecisionConfig
config = PipelineConfig(optimization_config=MixedPrecisionConfig())
chatbot = build_chatbot(config)
response = chatbot.predict(query="Tell me about Intel Xeon Scalable Processors.")
print(response)

response1 = chatbot.predict(query="What is AMD Ryzen?")
print(response1)

response2 = chatbot.predict(query="What is the difference between ARM and x86 architectures?")
print(response2)

response3 = chatbot.predict(query="Can you explain what a GPU is?")
print(response3)

response4 = chatbot.predict(query="What is the role of a motherboard in a computer?")
print(response4)

"""## Text Chat With Retrieval Plugin

User could also leverage NeuralChat Retrieval plugin to do domain specific chat by feding with some documents like below:
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd ./intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/pipeline/plugins/retrieval/
!pip install -r requirements.txt
# %cd ../../../../../../

# Commented out IPython magic to ensure Python compatibility.
!mkdir docs
# %cd docs
!curl -OL https://raw.githubusercontent.com/intel/intel-extension-for-transformers/main/intel_extension_for_transformers/neural_chat/assets/docs/sample.jsonl
!curl -OL https://raw.githubusercontent.com/intel/intel-extension-for-transformers/main/intel_extension_for_transformers/neural_chat/assets/docs/sample.txt
!curl -OL https://raw.githubusercontent.com/intel/intel-extension-for-transformers/main/intel_extension_for_transformers/neural_chat/assets/docs/sample.xlsx
# %cd ..

from intel_extension_for_transformers.neural_chat import PipelineConfig
from intel_extension_for_transformers.neural_chat import build_chatbot
from intel_extension_for_transformers.neural_chat import plugins
plugins.retrieval.enable=True
plugins.retrieval.args["input_path"]="./docs/"
config = PipelineConfig(plugins=plugins)
chatbot = build_chatbot(config)
response = chatbot.predict("How many cores does the IntelÂ® XeonÂ® Platinum 8480+ Processor have in total?")
print(response)

"""## Voice Chat with ASR & TTS Plugin

In the context of voice chat, users have the option to engage in various modes: utilizing input audio and receiving output audio, employing input audio and receiving textual output, or providing input in textual form and receiving audio output.

For the Python API code, users have the option to enable different voice chat modes by setting ASR and TTS plugins enable or disable.
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd ./intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/pipeline/plugins/audio/
!pip install -r requirements.txt
# %cd ../../../../../../

!curl -OL https://raw.githubusercontent.com/intel/intel-extension-for-transformers/main/intel_extension_for_transformers/neural_chat/assets/speaker_embeddings/spk_embed_default.pt
!curl -OL https://raw.githubusercontent.com/intel/intel-extension-for-transformers/main/intel_extension_for_transformers/neural_chat/assets/audio/sample.wav

from intel_extension_for_transformers.neural_chat import PipelineConfig
from intel_extension_for_transformers.neural_chat import build_chatbot
from intel_extension_for_transformers.neural_chat import plugins
plugins.tts.enable = True
plugins.tts.args["output_audio_path"] = "./response.wav"
plugins.asr.enable = True

config = PipelineConfig(plugins=plugins)
chatbot = build_chatbot(config)
result = chatbot.predict(query="./sample.wav")
print(result)

"""# Low Precision Optimization

## BF16
"""

# BF16 Optimization
from intel_extension_for_transformers.neural_chat.config import PipelineConfig
from intel_extension_for_transformers.transformers import MixedPrecisionConfig
config = PipelineConfig(optimization_config=MixedPrecisionConfig())
chatbot = build_chatbot(config)
response = chatbot.predict(query="Tell me about Intel Xeon Scalable Processors.")
print(response)
